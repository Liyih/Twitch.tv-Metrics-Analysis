{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: AdmiralBahroo\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-381415a5c1c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0msub_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msub_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m#bypass timeout against web crawlers (2-3 minutes for safety, total expected time ~2 hours)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m180\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0msub_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../generated_data/channelsubdata.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Scrapes channel subscription data from Twitchtracker\n",
    "import urllib.request as urllib\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#Pull our existing data\n",
    "ag_df = pd.read_csv(\"../../generated_data/TotalChannelData.csv\")\n",
    "\n",
    "channels = ag_df[\"Channel\"].unique()\n",
    "sub_df = pd.DataFrame()\n",
    "\n",
    "for channel in channels:\n",
    "    #bypass 403 forbidden against web crawlers\n",
    "    url = \"https://twitchtracker.com/\" + channel + \"/subscribers\"\n",
    "\n",
    "    print(\"Processing: \" + channel)\n",
    "    req = Request(url, headers={'User-Agent': 'Chrome/51.0.2704.103'})\n",
    "    html = urlopen(req).read()\n",
    "\n",
    "    soup = BeautifulSoup(html)\n",
    "\n",
    "    table = soup.find(id=\"subscribers\");\n",
    "    #Only pull data for channels that do have subscribers\n",
    "    if table is not None:\n",
    "        rows = table.find_all(\"tr\");\n",
    "        for row in rows:\n",
    "            data = row.find_all(\"td\");\n",
    "            #Knowing the structure of the table, process all valid rows in standard order\n",
    "            #Append each processed data item to our dataframe\n",
    "            if len(data) != 0:\n",
    "                month = data[0].get_text().strip()\n",
    "                total = data[1].get_text().strip()\n",
    "                prime = data[2].get_text().strip()\n",
    "                Tier1 = data[3].get_text().strip()\n",
    "                Tier2 = data[4].get_text().strip()\n",
    "                Tier3 = data[5].get_text().strip()\n",
    "                Unshared = data[6].get_text().strip()\n",
    "                # Income calculate the total dollar amounts based on the subscriber payments of the Tiers \n",
    "                Income = (int(Tier1)*4.99) + (int(Tier2)*9.99) + (int(Tier3)*24.99)\n",
    "\n",
    "                data_dict = {\"Channel\": channel, \"Month\" : month, \"Total\": total, \n",
    "                             \"Prime\": prime, \"Tier 1\": Tier1, \"Tier 2\": Tier2, \"Tier 3\": Tier3, \n",
    "                             \"Unshared\": Unshared, \"Total Income\": '${:,.2f}'.format(Income)}\n",
    "                sub_df = sub_df.append(data_dict, ignore_index=True)\n",
    "    #bypass timeout against web crawlers (2-3 minutes for safety, total expected time ~2 hours)\n",
    "    sleep(randint(120, 180))\n",
    "\n",
    "sub_df.to_csv(\"../../generated_data/channelsubdata.csv\")\n",
    "sub_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
