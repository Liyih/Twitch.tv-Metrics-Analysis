{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AdmiralBahroo' 'AdmiralBulldog' 'Castro_1021' 'CohhCarnage'\n",
      " 'DrDisrespect' 'DrLupo' 'ESL_CSGO' 'Fextralife' 'Fresh' 'GRONKH' 'Gorgc'\n",
      " 'Gotaga' 'LCK_Korea' 'LIRIK' 'Lord_Kebun' 'MOONMOON' 'Maximilian_DOOD'\n",
      " 'MontanaBlack88' 'NICKMERCS' 'NoWay4u_Sir' 'OgamingLoL' 'Solary'\n",
      " 'SolaryFortnite' 'Stray228' 'TFBlade' 'Tfue' 'TimTheTatman'\n",
      " 'Trainwreckstv' 'Trymacs' 'Vader' 'Yassuo' 'YoDa' 'alanzoka' 'dakotaz'\n",
      " 'dasMEHDI' 'forsen' 'gaules' 'lestream' 'loltyler1' 'nl_Kripp'\n",
      " 'sodapoppin' 'summit1g' 'xQcOW' 'ybicanoooobov' 'saddummy' 'hanryang1125']\n"
     ]
    }
   ],
   "source": [
    "#Testing scraper for Twitchtracker\n",
    "import urllib.request as urllib\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#Pull our existing data\n",
    "ag_df = pd.read_csv(\"created/TotalChannelData.csv\")\n",
    "\n",
    "channels = ag_df[\"Channel\"].unique()\n",
    "sub_df = pd.DataFrame()\n",
    "\n",
    "for channel in channels:\n",
    "    #bypass 403 forbidden against web crawlers\n",
    "    url = \"https://twitchtracker.com/\" + channel + \"/subscribers\"\n",
    "\n",
    "    print(\"Processing: \" + channel)\n",
    "    req = Request(url, headers={'User-Agent': 'Chrome/51.0.2704.103'})\n",
    "    html = urlopen(req).read()\n",
    "\n",
    "    soup = BeautifulSoup(html)\n",
    "\n",
    "    table = soup.find(id=\"subscribers\");\n",
    "    if table is not None:\n",
    "        rows = table.find_all(\"tr\");\n",
    "        for row in rows:\n",
    "            data = row.find_all(\"td\");\n",
    "            #Knowing the structure of the table, process all valid rows in standard order\n",
    "            #Append each processed data item to our dataframe\n",
    "            if len(data) != 0:\n",
    "                month = data[0].get_text().strip()\n",
    "                total = data[1].get_text().strip()\n",
    "                prime = data[2].get_text().strip()\n",
    "                Tier1 = data[3].get_text().strip()\n",
    "                Tier2 = data[4].get_text().strip()\n",
    "                Tier3 = data[5].get_text().strip()\n",
    "                Unshared = data[6].get_text().strip()\n",
    "                #Gifted = data[7].get_text().strip()\n",
    "                # Income calculate the total dollar amounts based on the subscriber payments of the Tiers \n",
    "                Income = (int(Tier1)*4.99) + (int(Tier2)*9.99) + (int(Tier3)*24.99)\n",
    "\n",
    "                data_dict = {\"Channel\": channel, \"Month\" : month, \"Total\": total, \n",
    "                             \"Prime\": prime, \"Tier 1\": Tier1, \"Tier 2\": Tier2, \"Tier 3\": Tier3, \n",
    "                             \"Unshared\": Unshared, \"Total Income\": '${:,.2f}'.format(Income)}\n",
    "                sub_df = sub_df.append(data_dict, ignore_index=True)\n",
    "    #bypass timeout against web crawlers (2-3 minutes for safety, total expected time ~2 hours)\n",
    "    sleep(randint(120, 180))\n",
    "\n",
    "sub_df.to_csv(\"channelsubdata.csv\")\n",
    "sub_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
